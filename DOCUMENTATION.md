# Templates documentation

## Before you begin

### Initial competences

The following competences are required (at a basic level) for this template to be useful.

- Unix
- LaTeX
- Git
- Python

Without these competences, it is still possible to contribute to an article
that uses this template, but it will be difficult to take the lead.

### Required software and configuration

It is assumed that you have installed and configured the following software,
ideally using your operating system's software installation tool
(app store, package manager, ..).

- Git: https://git-scm.com/
- The cookiecutter: https://www.cookiecutter.io/
- Inkscape: https://inkscape.org/
- TexLive 2021: https://tug.org/texlive/
- latexmk: https://personal.psu.edu/~jcc8/software/latexmk/
- A Text editor compatible with [editorconfig](https://editorconfig.org/)

Furthermore, it is assumed that you do not have a Pip or Conda environment
active by default in `~/.bashrc` (or similar initialization script).
When using Conda, make sure you have no `~/.condarc` or `~/.mambarc` file.

A new dedicated environment is created for every manuscript,
which may not play well with such "always active" environments.
Such defaults thwart reproducibility,
because others may not have the same global settings.

Everything should work on Linux, macOS and WSL.
It may also work natively on Windows (one day).


## Getting started

Initialize a new Git repository with the [cookiecutter](https://github.com/cookiecutter/cookiecutter):

```bash
cookiecutter https://github.com/reproducible-reporting/templates
```

Follow the instructions on the terminal. You will have to enter:

- `slug`.
  This a short name for the directory name containing all the sources and compiled outputs.
  Use lower-case characters, digits and hyphens only.
- `article`.
  The LaTeX article template you want to use.
- `cover`
  The LaTeX template for the cover letter.
- `env`.
  The software environment used for data post-processing and analysis.
  Use `pip` if that works for you.
  Use `micromamba` otherwise.

Enter the newly created directory (`slug`).
Add minimal dependencies for post-processing and plotting to `requirements.txt` or `environment.yaml`.
Once the dependencies are set, install the software environment.

```bash
./setup-env.sh
```

To activate your dedicated software environment, run

```bash
source env/bin/activate
```

(This activation is needed whenever you open a new terminal.)
Now you should be able to build the template manuscript and related documents with RepRepBuild as follows:

```bash
cd latest-draft
rr
```

When you are editing the source, the command `rrr` can be convenient.
It will continuously rebuild the publication every time you save a file,

Finally, we need to initialize the new directory as a Git repository.
First go back to the top-level directory (`slug`), where you initialize the repository.

```bash
cd ..
git init
```

Activate `pre-commit`, add all files and check if everything is ok

```bash
pre-commit install
git add .
pre-commit run --all
git status
```

None of the files generated by `rr` should be staged.
If all looks good, you can make the first commit:

```bash
git commit -a -m "Initial commit"
```

You should also have a remote repository, which can be shared with your co-authors.
Once that is set up:

```bash
git remote add origin 'remote url'
```

where you replace `'remote url'` by the correct one, which depends on your situation.


## Template conventions

Several template conventions are listed in the following subsections.
They are needed for several reasons:

- Make it easy for everyone to find files and work with them.
- Make it possible for RepRepBuild to rebuild the publication efficiently
  (without extensive configuration).
- Make it possible to reproduce the work.

Some of these conventions are imposed and fixed by `pre-commit`.

### General

For file names:

- No whitespace in file and directory names.
- All file and directory names use the ASCII character set.

For text files:

- The UTF-8 character set is always used for the contents.
- No trailing white space, no trailing empty lines.
- Unix end-of-line conventions: `\n`.
- Text files end with a single `\n`.


### Directory layout

For all important versions (submitted, preprint, etc),
a directory `YYYY-MM-DD-description` is created, containing the following:
- `latex-<prefix>/`: a LaTeX document, where `<prefix>` can be, e.g., `article`, `si` or `cover`.
  - The file `<prefix>.tex` contains the main LaTeX document.
  - All files needed to compile the LaTeX source should be in the top level directory.
    Do not use subdirectories, because these are not supported on all submission platforms.
  - Each figure must be one file, because some publishers require this.
  - Use PDF or high-resolution PNG files for figures.
  - Also include the sources of the PDF or PNG figures.
    SVG files drawn in Inkscape are converted by `rr` to PDF,
    such that you only need to commit the SVG.
    Figures of plots should not be commited to Git either.
    Commit the scripts to generate these plots instead,
    as explained below.
  - `latexmk <prefix>` should compile everything,
    provided the required files, such as plots, are generated.
- `dataset-<name>`:
  The raw data directories, e.g. those used for making plots.
  Always document this file with a `README.md`
  These data are zipped by `rr` for later upload to a data repository.
- `results-<name>`:
  Directory with scripts to generate one or more plots or a tables.
  When possible, make multiple of these directories to modularize the post-processing.
- `uploads/`: The files uploaded to the publisher, pre-print server and/or data repository.
- `uploads/downloads/`: The files for author approval, downloaded from the publisher or pre-print server.

When the source is being edited, a directory `latest-draft` with the same structure is used,
without a date prefix.
Whenever some relevant milestone is reached, or prior to some drastic change,
a time-stamped snapshot of `latest-draft` can be made,
named `YYYY-MM-DD-draft-milestone-something`.
Similarly, one may use directories for `submitted`, `revised`, `accepted`, `preprint`, etc.
All directory names with a date prefix are essentially frozen.

One could argue that Git already keeps track of all version.
Still having access to all important versions, without going through the revision history,
is convenient, e.g. when making edit traces.
It also lowers the burden for collaborators less proficient with Git.

More details on each directory type can be found in separate `README.md` documents,
which are also copied when you use the Cookiecutter:

- `dataset-example/README.md`
- `results-example/README.md`
- `uploads/README.md`
- `uploads/downloads/README.md`


## Usage

### Activate script

Whenever you start a new terminal, you need to run `source env/bin/activate` to use `rr`.
If this bothers you, do not put such things in your `~/.bashrc`.
User [direnv](https://github.com/direnv/direnv) instead.


### Keep clean

- [`pre-commit`](https://pre-commit.com) is used to remove trivial changes, which reduces diff noise.
  Install pre-commit and activate it on every clone of the repository.
- Remove all stale files (defined in `.gitignore`) with `git clean -dfX`
- Remove transient files for a specific LaTeX document: `latexmk -C <document>`.
- Remove all


### Minimal requirements for a pull request

(In the long run, our pre-commit should check for these minimal requirements.)

- Run `rr` after making changes and commit the files in the `uploads` directory.
  Always commit changes to the source together with their result on the `uploads`.
  Compiled PDFs or other intermediate files are not committed to the Git repository.
- Use meaningful and short commit messages.
- `pre-commit` must pass on each commit.
- At least one sentence explaining the pull request.


## Data policies

This section contains some instructions to facilitate data reuse and reproducibility.

For each section, the core idea is to store as much source material as possible.
When a file is larger than 5 MB, use Git LFS.

### Tex sources

Must:

- Everything is written in LaTeX.
- Every package you don't use is a good package.
- Every sentence ends with a newline character.
- To facilitate reviewing the PDF, use single-column and double line spacing.

Should:

- Some pakcages, like `todo` are convenient while writing.
  Clearly separate these from other `\usepackage` lines, so they can be easily deleted
  when finalizing the manuscript.
- Define as little commands as possible.
- Avoid low-quality publisher article classes. (ACS has a decent one.)


### Figures

Must:

- Separate data generation or collection from actual plotting.
  (Do these in two separate Python scripts.)
  This means you commit the following to Git:
  - Data files containing the data shown in the plots.
    Text files like CSV are preferred when possible.
    Also commit these when the data is auto-generated.
  - Scripts that generate data.
  - Scripts to generate the plot, using the above data as input.
    Use matplotlib unless you have good reasons not to.
  - A `README.md` summarizing the scripts and the data.
- When making drawings, use Inkscape and commit the SVG source files.
- Use bitmap formats only as an intermediate format when the vector graphics PDF show performance issues.
  This typically happens when a plot contains many thousands of data points.
  Always use PNG.

Things to avoid:

- Jupyter notebooks

### Tables

Must:

- Commit the following:
  - Machine-readable files containing the data shown in the table, e.g. CSV.
  - Scripts to generate the LaTeX source of table.
  - A `README.md` summarizing the scripts and the data.

Things to avoid:

- Jupyter notebooks


### Data sets

Must:

- Only use `dataset-<name>` directories when appropriate:
  - External data sets.
  - Super expensive calculations that you carried out separately.
  - Data generated with closed-source software.
    (Avoid such software when you have the choice.)
- Use semantic file and directory names to organize your data.
- Add as much as possible scripts and implementations to regenerate the data,
  with exactly the same file and directory names as in the data set.
- Add a `README.md` file explaining the following:
  - How was the data computed or collected.
  - Which software + version was used.
  - How are the files and directories organized.
  - If needed, which conventions are used inside the files.
- Data sets are Zipped in the end, so store uncompressed data in the repository.

Should:

- When data sets become to large to store on Git LFS,
  store the data on an appropriate UGent share.
  When doing so, make a TAR archive instead of copying individual files.
  The UGent shares run on a Windows platform,
  which cannot handle certain file permissions.

Things to avoid:

- Jupyter notebooks
- Inventing your own file format.
- Tar files, especially compressed ones.
  These are prone to data loss in case of even the tiniest bit rot.
  Ordinary ZIP is more robust, because every file is compressed individually.
- Compressed files inside compressed files.
- Binary files in general, are harder to reuse in the longer term.
- HDF5 files due to their data integrity issues.
- Python pickle files,
  as these can only be loaded when the corresponding Python packages are around.
  This is too limiting for long-term data preservation.
- Files that can only be used with closed-source software.


### Software

Must:

- List external software dependencies in `requirements.txt` or `environment.yaml`,
  such that they can be installed with `pip` or `conda` by all co-authors.
  Specify the version (if relevant).

- All software to rebuild the publication must be open source.

- When you have the choice, do not use closed-source software.

- If you generate some data with closed-source software, store it in a `dataset-<name>`
  directory and document in the `README.md` how you exactly generated the data
  and with which versions of the software.

- If you write your own Python package and use it in a publication,
  make open-source releases of all versions used in the paper.
  In addition to `requirements.txt` or `environment.yaml`,
  also refer to the source repository and the version of your package in the `README.md`
  of the corresponding `results-<name>` directories.

  If you Python package is highly experimental and you're not comfortable releasing it yet,
  you can include it in the publication repository,
  for example, under `latest-draft/pkgs/your_package`.
  You can then add `pip install -e latest-draft/pkgs/your_package` to the `setup-env.sh` script.
